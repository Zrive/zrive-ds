{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First af all we are going to include and import all modules we need for our analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from io import BytesIO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have our credentials stored in a .env file that has been also included in the gitignore file for privacy purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(\"credentials.env\")\n",
    "\n",
    "aws_access_key = os.getenv('AWS_ACCESS_KEY_ID')\n",
    "aws_secret_key = os.getenv('AWS_SECRET_ACCESS_KEY')\n",
    "aws_region = os.getenv('AWS_DEFAULT_REGION')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part is for initialating our access to S3 via boto3 client. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "groceries/sampled-datasets/abandoned_carts.parquet\n",
      "groceries/sampled-datasets/inventory.parquet\n",
      "groceries/sampled-datasets/orders.parquet\n",
      "groceries/sampled-datasets/regulars.parquet\n",
      "groceries/sampled-datasets/users.parquet\n"
     ]
    }
   ],
   "source": [
    "# Initialize S3 client\n",
    "s3 = boto3.client(\n",
    "    's3',\n",
    "    aws_access_key_id=os.getenv('AWS_ACCESS_KEY_ID'),\n",
    "    aws_secret_access_key=os.getenv('AWS_SECRET_ACCESS_KEY'),\n",
    "    region_name=os.getenv('AWS_DEFAULT_REGION')\n",
    ")\n",
    "\n",
    "# Define the bucket and prefix\n",
    "bucket_name = 'zrive-ds-data'\n",
    "prefix = 'groceries/sampled-datasets/'\n",
    "\n",
    "# List objects in the S3 bucket\n",
    "response = s3.list_objects_v2(Bucket=bucket_name, Prefix=prefix)\n",
    "\n",
    "# Print the list of files\n",
    "if 'Contents' in response:\n",
    "    for obj in response['Contents']:\n",
    "        print(obj['Key'])\n",
    "else:\n",
    "    print(\"No files found in the bucket.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are importing our datasets from parquet to Pandas for betteer handling of the information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file you want to download (e.g., orders.parquet)\n",
    "\n",
    "orders = 'groceries/sampled-datasets/orders.parquet'\n",
    "regulars ='groceries/sampled-datasets/regulars.parquet'\n",
    "inventory = 'groceries/sampled-datasets/inventory.parquet'\n",
    "abandoned_carts = 'groceries/sampled-datasets/abandoned_carts.parquet'\n",
    "users= 'groceries/sampled-datasets/users.parquet'\n",
    "\n",
    "# Download the Parquet file from S3\n",
    "\n",
    "response_orders = s3.get_object(Bucket=bucket_name, Key=orders)\n",
    "response_regulars = s3.get_object(Bucket=bucket_name, Key=regulars)\n",
    "response_inventory = s3.get_object(Bucket=bucket_name, Key=inventory)\n",
    "response_abandoned_carts = s3.get_object(Bucket=bucket_name, Key=abandoned_carts)\n",
    "response_users = s3.get_object(Bucket=bucket_name, Key=users)\n",
    "\n",
    "# Load the Parquet file into a Pandas DataFrame\n",
    "df_orders = pd.read_parquet(BytesIO(response_orders['Body'].read()))\n",
    "df_regulars = pd.read_parquet(BytesIO(response_regulars['Body'].read()))\n",
    "df_inventory = pd.read_parquet(BytesIO(response_inventory['Body'].read()))\n",
    "df_abandoned_carts = pd.read_parquet(BytesIO(response_abandoned_carts['Body'].read()))\n",
    "df_users = pd.read_parquet(BytesIO(response_users['Body'].read()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we Can start studying our datasets. First of all we want to understand what variables we have in each of our data-sets and get the first conclusions. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 8773 entries, 10 to 64538\n",
      "Data columns (total 6 columns):\n",
      " #   Column          Non-Null Count  Dtype         \n",
      "---  ------          --------------  -----         \n",
      " 0   id              8773 non-null   int64         \n",
      " 1   user_id         8773 non-null   object        \n",
      " 2   created_at      8773 non-null   datetime64[us]\n",
      " 3   order_date      8773 non-null   datetime64[us]\n",
      " 4   user_order_seq  8773 non-null   int64         \n",
      " 5   ordered_items   8773 non-null   object        \n",
      "dtypes: datetime64[us](2), int64(2), object(2)\n",
      "memory usage: 479.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df_orders.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First conclusion we can draw is that there are no-nulls in our oders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 18105 entries, 3 to 37720\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype         \n",
      "---  ------      --------------  -----         \n",
      " 0   user_id     18105 non-null  object        \n",
      " 1   variant_id  18105 non-null  int64         \n",
      " 2   created_at  18105 non-null  datetime64[us]\n",
      "dtypes: datetime64[us](1), int64(1), object(1)\n",
      "memory usage: 565.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df_regulars.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
